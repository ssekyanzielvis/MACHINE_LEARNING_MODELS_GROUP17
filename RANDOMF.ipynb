{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce8e346-9c6d-4431-8be3-420bd13d2a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic labels for testing purposes...\n",
      "Training the Random Forest Classifier with Grid Search...\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_and_preprocess_data(file_path, synthetic_labels=False):\n",
    "    \"\"\"\n",
    "    Load and preprocess the dataset from a CSV file.\n",
    "    Optionally generate synthetic labels for testing purposes.\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "    # Extract features (ECG signals)\n",
    "    X = df[['MLII', 'V5']].values  # Features: MLII and V5\n",
    "\n",
    "    # Handle labels\n",
    "    if 'label' in df.columns:\n",
    "        y = df['label'].values  # Use existing labels if available\n",
    "    elif synthetic_labels:\n",
    "        print(\"Generating synthetic labels for testing purposes...\")\n",
    "        y = np.random.randint(0, 5, size=len(X))  # Generate random labels (0 to 4)\n",
    "    else:\n",
    "        raise ValueError(\"The dataset does not contain a 'label' column. Please ensure labels are included.\")\n",
    "\n",
    "    # Encode categorical labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)  # Encode labels into integers\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scale the features (standardize to zero mean and unit variance)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, label_encoder.classes_\n",
    "\n",
    "def train_random_forest_with_grid_search(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train a Random Forest classifier with grid search for hyperparameter tuning.\n",
    "    \"\"\"\n",
    "    print(\"Training the Random Forest Classifier with Grid Search...\")\n",
    "    # Initialize the Random Forest model\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    # Initialize Grid Search\n",
    "    grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid,\n",
    "                               cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "    # Perform Grid Search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best model\n",
    "    best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    return best_rf_model\n",
    "\n",
    "def evaluate_model(rf_model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of the Random Forest model.\n",
    "    \"\"\"\n",
    "    print(\"Evaluating the Random Forest Model...\")\n",
    "    # Make predictions\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Print confusion matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "def analyze_feature_importance(rf_model, feature_names):\n",
    "    \"\"\"\n",
    "    Analyze and visualize feature importance from the Random Forest model.\n",
    "    \"\"\"\n",
    "    print(\"Analyzing Feature Importance...\")\n",
    "    # Get feature importances\n",
    "    importances = rf_model.feature_importances_\n",
    "\n",
    "    # Create a DataFrame for visualization\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Print feature importance\n",
    "    print(\"\\nFeature Importance:\")\n",
    "    print(feature_importance_df)\n",
    "\n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='skyblue')\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Feature Importance Analysis')\n",
    "    plt.gca().invert_yaxis()  # Invert y-axis for better readability\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess the dataset\n",
    "    file_path = \"C:/Users/abdulssekyanzi/EDA Dataset.csv/100.csv\"  # Replace with your dataset path\n",
    "    X_train, X_test, y_train, y_test, class_names = load_and_preprocess_data(file_path, synthetic_labels=True)\n",
    "\n",
    "    # Train the Random Forest model with grid search\n",
    "    best_rf_model = train_random_forest_with_grid_search(X_train, y_train)\n",
    "\n",
    "    # Evaluate the best model\n",
    "    evaluate_model(best_rf_model, X_test, y_test)\n",
    "\n",
    "    # Analyze feature importance\n",
    "    feature_names = ['MLII', 'V5']  # Replace with actual feature names if different\n",
    "    analyze_feature_importance(best_rf_model, feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9168f58f-21e4-4f96-8081-df6c72d446fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
